import streamlit as st
from langchain.memory.buffer import ConversationBufferMemory
from utils import qa_agent

st.title("ğŸ“„ AIæ™ºèƒ½PDFé—®ç­”å·¥å…·")

# ä¾§è¾¹æ 
with st.sidebar:
    api_key = st.text_input("è¯·è¾“å…¥DeeepSeek APIå¯†é’¥", type="password")
    st.markdown("[è·å–DeepSeek APIå¯†é’¥](https://platform.deepseek.com/api_keys)")

# æ·»åŠ è®°å¿†
if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history",
        output_key="answer"
        )

# ä¸Šä¼ æ–‡ä»¶å¹¶æé—®  
uploaded_file = st.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶", type="pdf")
question = st.text_input("å¯¹PDFæ–‡ä»¶è¿›è¡Œæé—®", disabled=not uploaded_file)

if uploaded_file and question and not api_key:
    st.info("è¯·è¾“å…¥DeeepSeek APIå¯†é’¥")

if uploaded_file and question and api_key:
    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
        response = qa_agent(api_key, st.session_state["memory"], uploaded_file, question)

    st.write("## ç­”æ¡ˆ")
    st.write(response["answer"])
    st.session_state["chat_history"] = response["chat_history"] 

if "chat_history" in st.session_state:
    with st.expander("å†å²æ¶ˆæ¯"):
        for i in range(0, len(st.session_state["chat_history"]), 2):
            human_message = st.session_state["chat_history"][i]
            ai_message = st.session_state["chat_history"][i + 1]
            st.write(f"human: {human_message.content}")
            st.write(f"ai: {ai_message.content}")
            if i < len(st.session_state["chat_history"]) - 2:
                st.divider()


